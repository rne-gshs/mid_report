\section{서론}
\subsection{연구 목적 및 필요성}
게임이론은 상호 의존적이고 이성적인 의사 결정에 대한 수학적 이론이다. 개인이나 기업이 어떤 행위를 했을 때, 그 결과가 자신 뿐만 아니라 다른 참가자의 행동에 의해서도 결정되는 상황에서, 자신의 최대 이익에 부합하는 행동을 추구한다는 수학적 이론을 연구한다.

블로토 대령 게임(Colonel Blotto Game)은 게임이론에서 연구되는 주요 문제 중 하나로, 두 참가자가 각각 제한된 병력을 여러 전장에 분배하여 각 전장에서 더 많은 병력을 배치한 참가자가 해당 전장에서 승리하며, 최종적으로 더 많은 전장에서 승리한 참가자가 승리하는 게임이다. 이러한 블로토 대령 게임은 국가간의 전쟁, 선거, 광고 투자, 경매와 같은 현실의 다양한 사회 현상에 적용할 수 있다. \cite{behnezhad2018battlefields}

블로토 대령 게임에 대한 대부분의 선행연구에서 서로 다른 전장의 중요도는 고려하지 않았다. 그러나 선거에서 여러 지역의 선거구의 중요도가 모두 같을 수는 없는 것처럼 현실의 사회 현상을 분석할 때 각 전장의 중요도를 고려할 필요가 있다. 또한, 각 참가자가 배치하는 병력의 능력 차에 따른 영향 역시 고려하여야 한다. 따라서 본 연구에서는 우선적으로 기존의 블로토 대령 게임을 분석하고, 이후 전장의 중요도에 따른 가중치를 부여하고 각 참가자의 전장 별 병력 효과를 다르게 한 확장된 블로토 대령 게임의 최적화된 전략을 도출할 것이다.

\subsection{이론적 배경}
\subsubsection{블로토 대령 게임(Colonel Blotto Game)}
먼저, 블로토 대령 게임의 규칙과 진행 방법을 수학적으로 정의하였다. 기본적인 형태의 블로토 대령 게임은 두 참가자가 각각 $k$명의 병력을 가진 상태에서 n개의 전장에 병력을 분배하여 각 전장에서 더 많은 병력을 배치한 참가자가 해당 전장에서 승리하며, 최종적으로 더 많은 전장에서 승리한 참가자가 승리하는 게임이다. 두 참가자를 A,B라 할때 $i$($1\le i\le n$)번째 전장에 A,B가 배치한 병력의 수를 각각 $a_i$, $b_i$라 하자.($\sum\limits_{i=1}^n a_i=k$, $\sum\limits_{i=1}^n b_i=k$, ${}_{}^{\forall}a_i, b_i \ge 0$)
이후 각 전장에서 승리여부를 판별하는 함수 $f$를 다음과 같이 설정했다.
$$f(x)=\begin{cases}
1, & x>0 \\
0, & x\le 0
\end{cases}$$
이때 A,B가 전장에서 승리한 횟수를 각각 $W_a=\sum\limits_{i=1}^n f(a_i-b_i)$, $W_b=\sum\limits_{i=1}^n f(b_i-a_i)$ 으로 나타낼 수 있고, $W_a>W_b$인 경우 A가 승리하며, $W_a<W_b$일때는 B가 승리한다. 또한 $W_a=W_b$인 경우에는 무승부가 된다.
\subsubsection{내시 균형(Nash Equilibrium)과 양자적 반응 균형(Quantal Response Equilibrium)}
내시 균형(Nash Equilibrium)은 게임 이론에서 상대방이 현재 전략을 유지한다는 전제 하에 나 자신도 현재 전략을 바꿀 유인이 없는, 서로가 자신의 전략을 바꾸지 않는 균형 상태를 일컫는 말이다. 게임 이론에서 내시 균형은 참가자들의 전략적인 상호작용을 분석할 때 사용되며, 그들에게 일어나는 행동 변화를 예측할 수 있는 방법을 제공한다. 이러한 내시 균형에는 다양한 형태의 변형 및 확장이 존재한다.

양자적 반응 균형(Quantal Response Equilibrium, 이하 QRE)은 참가자가 완벽하게 최적의 전략을 선택하지 않고 확률적으로 반응하는 상황을 설명하는 게임 이론에서의 균형 개념이다. 일반적인 내시 균형에서는 각 참가자가 상대방에 대한 최선의 반응을 선택한다고 가정한다. 하지만 실제 세계에서는 참가자들이 심리적 요인과 같은 이유로 항상 최선의 전략을 선택하지는 않을 것이다. QRE을 통해 이러한 상황을 고려하여 참가자가 어떠한 전략을 선택할 확률이 전략의 '가치'에 영향을 받은 확률적인 전략 선택 모델을 도출하고, 그 균형점을 찾을 수 있다.

QRE는 다음과 같은 과정을 거쳐 계산된다.
\\
1. 각 참가자가 어떠한 전략을 선택하였을 때 얻을 수 있는 기대 이익(payoff)을 계산한다.

2. Quantal Response 함수를 통해 참가자가 어떠한 전략을 선택할 확률을 결정한다. 일반적으로 Quantal Response 함수로 Logit 함수와 Probit 함수를 사용하나, Probit 함수의 경우 전략의 이익이 정규 분포를 따른다는 가정이 내제되어 있어 블로토 대령 게임에 적용하기 부적합하다. 따라서 본 연구에서는 Quantal Response 함수로 Logit 함수를 사용하였다. Logit 함수의 일반적인 꼴은 다음과 같다.

$$
P(s)=\cfrac{e^{\lambda U(s)}}{\sum e^{\lambda U(s)}}
$$
\\
위의 식에서 $s$는 선택 가능한 전략, $P(s)$는 모델이 전략 $s$를 선택할 확률, $U(s)$는 전략 $s$를 선택하였을 때 기대할 수 있는 이익을 의미한다. $\lambda$는 음이 아닌 실수 값을 갖는 파라미터로 모델의 '이성적' 정도를 나타낸다. 0인 경우 완전 무작위하게 전략을 선택하며, 그 값이 커질수록 모델이 더욱 전략의 기대 이익을 잘 반영한다.

3. 각 참가자의 Quantal Response 함수를 사용하여 QRE를 찾는다. 각 참가자가 상대방의 전략 선택 모델에 대한 자신의 Quantal Response를 계산하고, 이를 자신의 현재 전략으로 업데이트하는 과정을 반복한다. 이러한 반복 과정을 모든 참가자의 전략 모델이 더이상 변하지 않을 때 중단하며, 그 때의 상태가 QRE를 이룬다고 할 수 있다.